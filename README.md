# ka + ba. AI agent runtime and UI control layer bundle.

## ka - AI agent runtime
> The ka (ð“‚“) was the Egyptian concept of the soul "vital essence".

This project implements a Go-based agent runtime designed to be compatible with the Agent-to-Agent (A2A) communication protocol. It provides both a command-line interface (`ka`) for direct interaction with a configured LLM and an HTTP server exposing A2A-compliant endpoints for task management and interaction.

The primary goal is to create a flexible and extensible runtime that can manage tasks, interact with LLMs (initially via LM Studio's OpenAI-compatible API), and potentially integrate with other tools and capabilities in the future.


## Features

*   **A2A HTTP Server:**
    *   Serves agent self-description at `/.well-known/agent.json`.
    *   Implements core A2A task endpoints:
        *   `/tasks/send`: Accepts tasks for asynchronous processing.
        *   `/tasks/sendSubscribe`: Accepts tasks and streams responses via Server-Sent Events (SSE).
        *   `/tasks/status`: Retrieves the status and details of a task.
        *   `/tasks/input`: Allows providing input to tasks waiting in the `input-required` state.
        *   `/tasks/artifact`: Retrieves artifacts generated by tasks.
        *   `/tasks/pushNotification/set`: Placeholder for push notification registration.
    *   Supports different input `Part` types (`TextPart`, `FilePart`, `DataPart`) for task submission.
        *   Basic handling for `file://` URIs in `FilePart` is included.
    *   Handles `input-required` state transitions based on LLM response markers.
*   **Task Management:**
    *   Defines a `Task` model with states (`submitted`, `working`, `input-required`, `completed`, `failed`, `canceled`).
    *   Includes both an `InMemoryTaskStore` (default, non-persistent) and a `FileTaskStore` (persistent, saves tasks as JSON files in `_tasks/`).
*   **`ka` Command-Line Tool:**
    *   Provides direct interaction with the configured LLM (requires LM Studio running).
    *   Supports piping input (`cat file | ka`).
    *   Supports streaming responses (`ka --stream "prompt"`).
    *   Can output the agent's self-description (`ka --describe`).
*   **LLM Integration:**
    *   Connects to OpenAI-compatible APIs (tested with LM Studio).
    *   Configurable via environment variables (see `llm/llm.go`).
    *   Supports streaming responses from the LLM.

## Getting Started

### Prerequisites

*   Go (version 1.22 or later recommended)
*   [LM Studio](https://lmstudio.ai/) installed and running (`lms server start`) for LLM interaction.

### Building

```bash
make build
```
This creates the `ka` executable in the project root.

### Running the A2A Server

```bash
./ka server
# Or using the default command:
# ./ka
```
This starts the HTTP server (defaulting to port 8080) using the `InMemoryTaskStore`.

To use the persistent `FileTaskStore`:
```bash
./ka server --task-store file --task-store-path ./my_tasks
```

The server exposes endpoints like:
*   `http://localhost:8080/.well-known/agent.json`
*   `http://localhost:8080/tasks/send` (POST)
*   `http://localhost:8080/tasks/sendSubscribe` (POST)
*   `http://localhost:8080/tasks/status?id={task_id}` (GET)
*   `http://localhost:8080/tasks/input` (POST)
*   ... and others.

### Using the `ka` CLI Tool

Ensure the `ka` binary is in your PATH or use the full path.

**Basic Interaction:**
```bash
./ka "Hello, world!"
```

**Streaming:**
```bash
./ka --stream "Tell me a story."
```

**Piping:**
```bash
cat README.md | ./ka ai "Summarize this file."
```

**Agent Description:**
```bash
./ka --describe
```

**Maximum Context Length:**
```bash
./ka --max_context_length 4096 "Hello, world!"
```

## Configuration

LLM connection details (API key, base URL, model) can be configured via environment variables (e.g., `LLM_API_KEY`, `LLM_API_BASE`, `LLM_MODEL`). See `llm/llm.go` for details.

## Development

*   **Code Structure:**
    *   `main.go`: Entrypoint for CLI commands and server startup.
    *   `http.go`: A2A HTTP server setup and agent card definition.
    *   `ai.go`: Implementation of the `ka` CLI command.
    *   `a2a/`: Package containing A2A protocol types (Task, Message, Part, Artifact), TaskStore interface/implementations, and HTTP handlers.
    *   `llm/`: Package for LLM client abstraction and interaction.
*   **Building:** `make build`
*   **Testing:** `make test` (or `go test ./...`)
*   **TODO:** See `TODO.md` for the current implementation status and planned features.

## Future Work

*   Implement task resumption logic for `input-required` state.
*   Full implementation of push notifications.
*   Support for more `Part` types and URI schemes (e.g., `http://`, `data://`).
*   Integration with MCP tools.
*   More robust error handling and input validation.
*   Comprehensive unit and integration tests.
*   Containerization improvements (health checks, etc.).



# ba - A2A Agent UI, Control, and Orchestration Layer

`ba` is a web application built with Vite and React, designed to serve as a user interface, control panel, and orchestration layer for Agent-to-Agent (A2A) compliant AI agents. It aims to provide a unified interface for interacting with various agents, including the local [ka](https://github.com/tot-ra/ka) agent runtime.

## Purpose

The primary goal of `ba` is to enable users to:

*   Manage and interact with A2A-compliant AI agents.
*   Spawn and control local instances of the `ka` agent.
*   Submit tasks to selected agents with various input types.
*   Monitor task status and view results, including streaming output and artifacts.
*   Eventually, orchestrate complex workflows involving multiple agents.

## Features

`ba` is being developed to include the following features (see [TODO.md](TODO.md) for detailed tasks and progress):

*   **Agent Management:** Add, remove, and list A2A agent endpoints.
*   **Local `ka` Control:** Spawn and stop local `ka` agent processes with configurable settings.
*   **Task Interaction:** Send tasks to selected agents, handle different input types (text, files, data), and receive/display streaming responses and final results.
*   **Task Monitoring:** View the status and history of tasks.
*   **Artifact Handling:** Retrieve and display artifacts generated by agents.
*   **Input Handling:** Provide necessary input to agents when a task requires it.
*   **Orchestration:** (Planned) Define and execute workflows involving multiple agents.
*   **Agent Discovery:** (Planned) Fetch and display agent capabilities from their Agent Cards (`/.well-known/agent.json`).

## A2A Agent Requirements

For effective interaction and future orchestration capabilities within `ba`, A2A-compliant agents are expected to implement the following standard endpoint:

*   **`/agents/update` (POST):** This endpoint, as defined in the A2A specification, allows `ba` (or other control layers) to inform an agent about the presence and details of other agents in the network. Implementing this is crucial for enabling features like agent-to-agent task delegation and collaborative workflows managed by `ba`.

## Getting Started

### Prerequisites

*   Node.js and npm/yarn/pnpm
*   Go (if you plan to spawn local `ka` agents)
*   An A2A-compliant agent running and accessible via a URL (e.g., a running `ka` instance).

### Setup

1.  Navigate to the `ba` directory:
    ```bash
    cd ba
    ```
2.  Install frontend dependencies:
    ```bash
    npm install # or yarn install or pnpm install
    ```
3.  Set up the backend for `ba`. The backend is necessary for spawning local `ka` processes and potentially proxying requests to handle CORS or other issues. The choice of backend technology is pending (see [TODO.md](TODO.md)). Follow the backend setup instructions once the technology is decided and implemented.

### Running the Application

1.  Start the `ba` frontend development server:
    ```bash
    npm run dev # or yarn dev or pnpm dev
    ```
    The application should now be running at `http://localhost:5173` (or another port if 5173 is in use).
2.  Ensure your A2A agent(s) (including `ka` if desired) are running and accessible.

## Project Structure

*   `/src`: Frontend source code (React/TypeScript).
*   `/backend`: Backend source code (will be created based on the chosen technology).
*   `TODO.md`: Detailed list of planned features and tasks.
*   `README.md`: This file.

## Contributing

Contributions are welcome! Please refer to the [TODO.md](TODO.md) for areas of development and the main project's contribution guidelines.

## License

[Specify License Here, e.g., MIT, Apache 2.0]
